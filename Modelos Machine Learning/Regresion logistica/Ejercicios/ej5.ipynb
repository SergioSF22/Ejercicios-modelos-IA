{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "None\n",
      "            User ID         Age  EstimatedSalary   Purchased\n",
      "count  4.000000e+02  400.000000       400.000000  400.000000\n",
      "mean   1.569154e+07   37.655000     69742.500000    0.357500\n",
      "std    7.165832e+04   10.482877     34096.960282    0.479864\n",
      "min    1.556669e+07   18.000000     15000.000000    0.000000\n",
      "25%    1.562676e+07   29.750000     43000.000000    0.000000\n",
      "50%    1.569434e+07   37.000000     70000.000000    0.000000\n",
      "75%    1.575036e+07   46.000000     88000.000000    1.000000\n",
      "max    1.581524e+07   60.000000    150000.000000    1.000000\n",
      "User ID: [15624510 15810944 15668575 15603246 15804002 15728773 15598044 15694829\n",
      " 15600575 15727311 15570769 15606274 15746139 15704987 15628972 15697686\n",
      " 15733883 15617482 15704583 15621083 15649487 15736760 15714658 15599081\n",
      " 15705113 15631159 15792818 15633531 15744529 15669656 15581198 15729054\n",
      " 15573452 15776733 15724858 15713144 15690188 15689425 15671766 15782806\n",
      " 15764419 15591915 15772798 15792008 15715541 15639277 15798850 15776348\n",
      " 15727696 15793813 15694395 15764195 15744919 15671655 15654901 15649136\n",
      " 15775562 15807481 15642885 15789109 15814004 15673619 15595135 15583681\n",
      " 15605000 15718071 15679760 15654574 15577178 15595324 15756932 15726358\n",
      " 15595228 15782530 15592877 15651983 15746737 15774179 15667265 15655123\n",
      " 15595917 15668385 15709476 15711218 15798659 15663939 15694946 15631912\n",
      " 15768816 15682268 15684801 15636428 15809823 15699284 15786993 15709441\n",
      " 15710257 15582492 15575694 15756820 15766289 15593014 15584545 15675949\n",
      " 15672091 15801658 15706185 15789863 15720943 15697997 15665416 15660200\n",
      " 15619653 15773447 15739160 15689237 15679297 15591433 15642725 15701962\n",
      " 15811613 15741049 15724423 15574305 15678168 15697020 15610801 15745232\n",
      " 15722758 15792102 15675185 15801247 15725660 15638963 15800061 15578006\n",
      " 15668504 15687491 15610403 15741094 15807909 15666141 15617134 15783029\n",
      " 15622833 15746422 15750839 15749130 15779862 15767871 15679651 15576219\n",
      " 15699247 15619087 15605327 15610140 15791174 15602373 15762605 15598840\n",
      " 15744279 15670619 15599533 15757837 15697574 15578738 15762228 15614827\n",
      " 15789815 15579781 15587013 15570932 15794661 15581654 15644296 15614420\n",
      " 15609653 15594577 15584114 15673367 15685576 15774727 15694288 15603319\n",
      " 15759066 15814816 15724402 15571059 15674206 15715160 15730448 15662067\n",
      " 15779581 15662901 15689751 15667742 15738448 15680243 15745083 15708228\n",
      " 15628523 15708196 15735549 15809347 15660866 15766609 15654230 15794566\n",
      " 15800890 15697424 15724536 15735878 15707596 15657163 15622478 15779529\n",
      " 15636023 15582066 15666675 15732987 15789432 15663161 15694879 15593715\n",
      " 15575002 15622171 15795224 15685346 15691808 15721007 15794253 15694453\n",
      " 15813113 15614187 15619407 15646227 15660541 15753874 15617877 15772073\n",
      " 15701537 15736228 15780572 15769596 15586996 15722061 15638003 15775590\n",
      " 15730688 15753102 15810075 15723373 15795298 15584320 15724161 15750056\n",
      " 15609637 15794493 15569641 15815236 15811177 15680587 15672821 15767681\n",
      " 15600379 15801336 15721592 15581282 15746203 15583137 15680752 15688172\n",
      " 15791373 15589449 15692819 15727467 15734312 15764604 15613014 15759684\n",
      " 15609669 15685536 15750447 15663249 15638646 15734161 15631070 15761950\n",
      " 15649668 15713912 15586757 15596522 15625395 15760570 15566689 15725794\n",
      " 15673539 15705298 15675791 15747043 15736397 15678201 15720745 15637593\n",
      " 15598070 15787550 15603942 15733973 15596761 15652400 15717893 15622585\n",
      " 15733964 15753861 15747097 15594762 15667417 15684861 15742204 15623502\n",
      " 15774872 15611191 15674331 15619465 15575247 15695679 15713463 15785170\n",
      " 15796351 15639576 15693264 15589715 15769902 15587177 15814553 15601550\n",
      " 15664907 15612465 15810800 15665760 15588080 15776844 15717560 15629739\n",
      " 15729908 15716781 15646936 15768151 15579212 15721835 15800515 15591279\n",
      " 15587419 15750335 15699619 15606472 15778368 15671387 15573926 15709183\n",
      " 15577514 15778830 15768072 15768293 15654456 15807525 15574372 15671249\n",
      " 15779744 15624755 15611430 15774744 15629885 15708791 15793890 15646091\n",
      " 15596984 15800215 15577806 15749381 15683758 15670615 15715622 15707634\n",
      " 15806901 15775335 15724150 15627220 15672330 15668521 15807837 15592570\n",
      " 15748589 15635893 15757632 15691863 15706071 15654296 15755018 15594041]\n",
      "Gender: ['Male' 'Female']\n",
      "Age: [19 35 26 27 32 25 20 18 29 47 45 46 48 49 31 21 28 33 30 23 24 22 59 34\n",
      " 39 38 37 42 40 36 41 58 55 52 60 56 53 50 51 57 44 43 54]\n",
      "EstimatedSalary: [ 19000  20000  43000  57000  76000  58000  84000 150000  33000  65000\n",
      "  80000  52000  86000  18000  82000  25000  26000  28000  29000  22000\n",
      "  49000  41000  23000  30000  74000 137000  16000  44000  90000  27000\n",
      "  72000  31000  17000  51000 108000  15000  79000  54000 135000  89000\n",
      "  32000  83000  55000  48000 117000  87000  66000 120000  63000  68000\n",
      " 113000 112000  42000  88000  62000 118000  85000  81000  50000 116000\n",
      " 123000  73000  37000  59000 149000  21000  35000  71000  61000  75000\n",
      "  53000 107000  96000  45000  47000 100000  38000  69000 148000 115000\n",
      "  34000  60000  70000  36000  39000 134000 101000 130000 114000 142000\n",
      "  78000 143000  91000 144000 102000 126000 133000 147000 104000 146000\n",
      " 122000  97000  95000 131000  77000 125000 106000 141000  93000 138000\n",
      " 119000 105000  99000 129000  46000  64000 139000]\n",
      "Purchased: [0 1]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Imprimimos los valores unicos de cada columna para analizar su contenido\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.05%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 87.50%\n",
      "Precision: 80.00%\n",
      "Recall: 85.71%\n",
      "F1-Score: 82.76%\n",
      "AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 88.75%\n",
      "Precision: 91.30%\n",
      "Recall: 75.00%\n",
      "F1-Score: 82.35%\n",
      "AUC-ROC: 96.77%\n",
      "\n",
      "El mejor método de balanceo es: SMOTE con F1-Score: 84.21% y AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.12%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 1, 'solver': 'liblinear'}\n",
      "Mejor Accuracy en validación cruzada: 84.88%\n",
      "Accuracy: 88.75%\n",
      "Precision: 82.76%\n",
      "Recall: 85.71%\n",
      "F1-Score: 84.21%\n",
      "AUC-ROC: 97.25%\n",
      "          Real   Predicción\n",
      "0  No Comprado  No Comprado\n",
      "1     Comprado     Comprado\n",
      "2  No Comprado  No Comprado\n",
      "3     Comprado     Comprado\n",
      "4  No Comprado  No Comprado\n",
      "5  No Comprado  No Comprado\n",
      "6     Comprado     Comprado\n",
      "7  No Comprado  No Comprado\n",
      "8  No Comprado     Comprado\n",
      "9  No Comprado     Comprado\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos la columna User ID ya que no aporta nada al modelo\n",
    "df = df.drop([\"User ID\"], axis=1)\n",
    "\n",
    "# Encodeamos las columnas con valores categóricos\n",
    "df[\"Gender\"] = pd.get_dummies(df[\"Gender\"], drop_first=True)\n",
    "\n",
    "# Eligimos la variable a predecir y las predictoras\n",
    "X = df.drop([\"Purchased\"], axis=1)\n",
    "y = df[\"Purchased\"]\n",
    "\n",
    "# Prepocesamos las varibales numéricas mediante el StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    # Creación del modelo de RL\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    # Entreno el modelo con los datos de cada modelo\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    # Realizo predicciones con el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculo la precisión del modelo sacando las métricas\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    # Imprimimos los resultados\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"No Comprado\", 1: \"Comprado\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"No Comprado\", 1: \"Comprado\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  7,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
      "       ...\n",
      "       388, 389, 390, 391, 392, 393, 395, 396, 397, 399],\n",
      "      dtype='int64', length=143)\n",
      "Gender              False\n",
      "Age                    32\n",
      "EstimatedSalary    150000\n",
      "Purchased               1\n",
      "Name: 7, dtype: object\n",
      "\n",
      "Ingrese los valores para realizar una predicción:\n",
      "\n",
      "Predicción: No comprado (91.29% de confianza)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SergioSF\\Desktop\\Programacion de Modelos de IA\\Ejercicios y apuntes\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --------------------\n",
    "# PRUEBA Y EJECUCIÓN DEL MODELO\n",
    "# --------------------\n",
    "\n",
    "\n",
    "# Buscamos un registro de un paciente con cancer para pasar los mismos datos y probar que el modelo predice correctamente\n",
    "print(df[df[\"Purchased\"] == 1].index) # Seleccionamos la 37\n",
    "print(df.loc[7])\n",
    "\n",
    "# Mapeo de características a nombres en castellano (opcional)\n",
    "nombres_caracteristicas = {\n",
    "    'Gender': 'Genero',\n",
    "    'Age': 'Edad',\n",
    "    'EstimatedSalary': 'Salario estimado',\n",
    "}\n",
    "\n",
    "# Creamos la función para ejecutar el modelo con nuevos datos\n",
    "def solicitar_datos_y_predecir(modelo, feature_names, scaler):\n",
    "    print(\"\\nIngrese los valores para realizar una predicción:\")\n",
    "    valores = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        nombre_caracteristica = nombres_caracteristicas.get(feature, feature)  \n",
    "        while True:\n",
    "            try:\n",
    "                valor = float(input(f\"{nombre_caracteristica}: \"))\n",
    "                valores.append(valor)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Entrada inválida. Ingrese un número válido.\")\n",
    "    \n",
    "    # Convertir la entrada en un array de numpy y escalarlo con el scaler ya entrenado\n",
    "    datos_nuevos = np.array(valores).reshape(1, -1)\n",
    "    datos_nuevos_escalados = scaler.transform(datos_nuevos)\n",
    "    \n",
    "    # Realizar predicción\n",
    "    prediccion = modelo.predict(datos_nuevos_escalados)[0]\n",
    "    probabilidad = modelo.predict_proba(datos_nuevos_escalados)[0][prediccion] * 100\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    resultado = \"Comprado\" if prediccion == 1 else \"No comprado\"\n",
    "    print(f\"\\nPredicción: {resultado} ({probabilidad:.2f}% de confianza)\\n\")\n",
    "\n",
    "# Llamar a la función con el scaler ya ajustado\n",
    "solicitar_datos_y_predecir(best_model, df.drop(columns=[\"Purchased\"]).columns, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
