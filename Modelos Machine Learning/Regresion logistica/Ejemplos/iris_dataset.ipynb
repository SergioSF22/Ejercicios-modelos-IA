{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius           mean perimeter          0.997855\n",
      "                      mean area               0.987357\n",
      "                      worst radius            0.969539\n",
      "                      worst perimeter         0.965137\n",
      "                      worst area              0.941082\n",
      "mean texture          worst texture           0.912045\n",
      "mean perimeter        mean radius             0.997855\n",
      "                      mean area               0.986507\n",
      "                      worst radius            0.969476\n",
      "                      worst perimeter         0.970387\n",
      "                      worst area              0.941550\n",
      "mean area             mean radius             0.987357\n",
      "                      mean perimeter          0.986507\n",
      "                      worst radius            0.962746\n",
      "                      worst perimeter         0.959120\n",
      "                      worst area              0.959213\n",
      "mean concavity        mean concave points     0.921391\n",
      "mean concave points   mean concavity          0.921391\n",
      "                      worst concave points    0.910155\n",
      "radius error          perimeter error         0.972794\n",
      "                      area error              0.951830\n",
      "perimeter error       radius error            0.972794\n",
      "                      area error              0.937655\n",
      "area error            radius error            0.951830\n",
      "                      perimeter error         0.937655\n",
      "worst radius          mean radius             0.969539\n",
      "                      mean perimeter          0.969476\n",
      "                      mean area               0.962746\n",
      "                      worst perimeter         0.993708\n",
      "                      worst area              0.984015\n",
      "worst texture         mean texture            0.912045\n",
      "worst perimeter       mean radius             0.965137\n",
      "                      mean perimeter          0.970387\n",
      "                      mean area               0.959120\n",
      "                      worst radius            0.993708\n",
      "                      worst area              0.977578\n",
      "worst area            mean radius             0.941082\n",
      "                      mean perimeter          0.941550\n",
      "                      mean area               0.959213\n",
      "                      worst radius            0.984015\n",
      "                      worst perimeter         0.977578\n",
      "worst concave points  mean concave points     0.910155\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  ...  worst fractal dimension  target\n",
       "0          17.99         10.38  ...                  0.11890       0\n",
       "1          20.57         17.77  ...                  0.08902       0\n",
       "2          19.69         21.25  ...                  0.08758       0\n",
       "3          11.42         20.38  ...                  0.17300       0\n",
       "4          20.29         14.34  ...                  0.07678       0\n",
       "..           ...           ...  ...                      ...     ...\n",
       "564        21.56         22.39  ...                  0.07115       0\n",
       "565        20.13         28.25  ...                  0.06637       0\n",
       "566        16.60         28.08  ...                  0.07820       0\n",
       "567        20.60         29.33  ...                  0.12400       0\n",
       "568         7.76         24.54  ...                  0.07039       1\n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df[\"target\"] = data.target  # 1 = Maligno, 0 = Benigno\n",
    "\n",
    "# Analizamos el contenido del DataFrame\n",
    "\"\"\"print(df.info())\n",
    "print(df.describe())\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {len(df[col].unique())}\")\"\"\"\n",
    "# Matriz de correlaci√≥n\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Filtrar valores mayores a 0.9 (excluyendo la diagonal)\n",
    "filtered = corr_matrix.where((corr_matrix > 0.9) & (corr_matrix < 1)).stack()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(filtered)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.80%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 97.37%\n",
      "Precision: 98.57%\n",
      "Recall: 97.18%\n",
      "F1-Score: 97.87%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 96.49%\n",
      "Precision: 97.18%\n",
      "Recall: 97.18%\n",
      "F1-Score: 97.18%\n",
      "AUC-ROC: 99.80%\n",
      "\n",
      "El mejor m√©todo de balanceo es: SMOTE con F1-Score: 98.59% y AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con ajuste manual de hiperpar√°metros:\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "\n",
      "Resultados con ajuste autom√°tico de hiperpar√°metros:\n",
      "Mejores par√°metros: {'C': 0.1, 'solver': 'lbfgs'}\n",
      "Mejor Accuracy en validaci√≥n cruzada: 98.08%\n",
      "Accuracy: 98.25%\n",
      "Precision: 98.59%\n",
      "Recall: 98.59%\n",
      "F1-Score: 98.59%\n",
      "AUC-ROC: 99.84%\n",
      "      Real Predicci√≥n\n",
      "0  Maligno    Maligno\n",
      "1  Benigno    Benigno\n",
      "2  Benigno    Benigno\n",
      "3  Maligno    Maligno\n",
      "4  Maligno    Maligno\n",
      "5  Benigno    Benigno\n",
      "6  Benigno    Benigno\n",
      "7  Benigno    Benigno\n",
      "8  Maligno    Maligno\n",
      "9  Maligno    Maligno\n"
     ]
    }
   ],
   "source": [
    "# Elejimos las variables predictoras y objetivo\n",
    "X = df.drop([\"target\"], axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Preprocesamos las columnas num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Divisi√≥n de datos entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------\n",
    "# M√âTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACI√ìN DE M√âTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    # Creaci√≥n del modelo de RL\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    # Entreno el modelo con los datos de cada modelo\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    # Realizo predicciones con el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculo la precisi√≥n del modelo sacando las m√©tricas\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    # Imprimimos los resultados\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor m√©todo de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor m√©todo de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor m√©todo encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# M√âTODO 1: Ajuste manual de hiperpar√°metros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperpar√°metros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluaci√≥n del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperpar√°metros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# M√âTODO 2: Ajuste autom√°tico con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularizaci√≥n\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimizaci√≥n\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar b√∫squeda de hiperpar√°metros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluaci√≥n del mejor modelo\n",
    "print(\"\\nResultados con ajuste autom√°tico de hiperpar√°metros:\")\n",
    "print(f\"Mejores par√°metros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validaci√≥n cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACI√ìN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicci√≥n\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"Benigno\", 1: \"Maligno\"})\n",
    "resultados[\"Predicci√≥n\"] = resultados[\"Predicci√≥n\"].map({0: \"Benigno\", 1: \"Maligno\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 19,  20,  21,  37,  46,  48,  49,  50,  51,  52,\n",
      "       ...\n",
      "       553, 554, 555, 556, 557, 558, 559, 560, 561, 568],\n",
      "      dtype='int64', length=357)\n",
      "mean radius                 13.030000\n",
      "mean texture                18.420000\n",
      "mean perimeter              82.610000\n",
      "mean area                  523.800000\n",
      "mean smoothness              0.089830\n",
      "mean compactness             0.037660\n",
      "mean concavity               0.025620\n",
      "mean concave points          0.029230\n",
      "mean symmetry                0.146700\n",
      "mean fractal dimension       0.058630\n",
      "radius error                 0.183900\n",
      "texture error                2.342000\n",
      "perimeter error              1.170000\n",
      "area error                  14.160000\n",
      "smoothness error             0.004352\n",
      "compactness error            0.004899\n",
      "concavity error              0.013430\n",
      "concave points error         0.011640\n",
      "symmetry error               0.026710\n",
      "fractal dimension error      0.001777\n",
      "worst radius                13.300000\n",
      "worst texture               22.810000\n",
      "worst perimeter             84.460000\n",
      "worst area                 545.900000\n",
      "worst smoothness             0.097010\n",
      "worst compactness            0.046190\n",
      "worst concavity              0.048330\n",
      "worst concave points         0.050130\n",
      "worst symmetry               0.198700\n",
      "worst fractal dimension      0.061690\n",
      "target                       1.000000\n",
      "Name: 37, dtype: float64\n",
      "\n",
      "Ingrese los valores para realizar una predicci√≥n:\n",
      "\n",
      "Predicci√≥n: Maligno (99.72% de confianza)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SergioSF\\Desktop\\Programacion de Modelos de IA\\Ejercicios y apuntes\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Buscamos un registro de un paciente con cancer para pasar los mismos datos y probar que el modelo predice correctamente\n",
    "print(df[df[\"target\"] == 1].index) # Seleccionamos la 37\n",
    "print(df.loc[37])\n",
    "\n",
    "# Mapeo de caracter√≠sticas a nombres en castellano (opcional)\n",
    "nombres_caracteristicas = {\n",
    "    'mean radius': 'Radio promedio',\n",
    "    'mean texture': 'Textura promedio',\n",
    "    'mean perimeter': 'Per√≠metro promedio',\n",
    "    'mean area': '√Årea promedio',\n",
    "    'mean smoothness': 'Suavidad promedio',\n",
    "    'mean compactness': 'Compacidad promedio',\n",
    "    'mean concavity': 'Concavidad promedio',\n",
    "    'mean concave points': 'Puntos c√≥ncavos promedio',\n",
    "    'mean symmetry': 'Simetr√≠a promedio',\n",
    "    'mean fractal dimension': 'Dimensi√≥n fractal promedio',\n",
    "    'radius error': 'Error de radio',\n",
    "    'texture error': 'Error de textura',\n",
    "    'perimeter error': 'Error de per√≠metro',\n",
    "    'area error': 'Error de √°rea',\n",
    "    'smoothness error': 'Error de suavidad',\n",
    "    'compactness error': 'Error de compacidad',\n",
    "    'concavity error': 'Error de concavidad',\n",
    "    'concave points error': 'Error de puntos c√≥ncavos',\n",
    "    'symmetry error': 'Error de simetr√≠a',\n",
    "    'fractal dimension error': 'Error de dimensi√≥n fractal',\n",
    "    'worst radius': 'Radio m√°ximo',\n",
    "    'worst texture': 'Textura m√°xima',\n",
    "    'worst perimeter': 'Per√≠metro m√°ximo',\n",
    "    'worst area': '√Årea m√°xima',\n",
    "    'worst smoothness': 'Suavidad m√°xima',\n",
    "    'worst compactness': 'Compacidad m√°xima',\n",
    "    'worst concavity': 'Concavidad m√°xima',\n",
    "    'worst concave points': 'Puntos c√≥ncavos m√°ximos',\n",
    "    'worst symmetry': 'Simetr√≠a m√°xima',\n",
    "    'worst fractal dimension': 'Dimensi√≥n fractal m√°xima'\n",
    "}\n",
    "\n",
    "# Creamos la funci√≥n para ejecutar el modelo con nuevos datos\n",
    "def solicitar_datos_y_predecir(modelo, feature_names, scaler):\n",
    "    print(\"\\nIngrese los valores para realizar una predicci√≥n:\")\n",
    "    valores = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        nombre_caracteristica = nombres_caracteristicas.get(feature, feature)  \n",
    "        while True:\n",
    "            try:\n",
    "                valor = float(input(f\"{nombre_caracteristica}: \"))\n",
    "                valores.append(valor)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Entrada inv√°lida. Ingrese un n√∫mero v√°lido.\")\n",
    "    \n",
    "    # Convertir la entrada en un array de numpy y escalarlo con el scaler ya entrenado\n",
    "    datos_nuevos = np.array(valores).reshape(1, -1)\n",
    "    datos_nuevos_escalados = scaler.transform(datos_nuevos)\n",
    "    \n",
    "    # Realizar predicci√≥n\n",
    "    prediccion = modelo.predict(datos_nuevos_escalados)[0]\n",
    "    probabilidad = modelo.predict_proba(datos_nuevos_escalados)[0][prediccion] * 100\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    resultado = \"Maligno\" if prediccion == 1 else \"Benigno\"\n",
    "    print(f\"\\nPredicci√≥n: {resultado} ({probabilidad:.2f}% de confianza)\\n\")\n",
    "\n",
    "# Llamar a la funci√≥n con el scaler ya ajustado\n",
    "solicitar_datos_y_predecir(best_model, data.feature_names, scaler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
