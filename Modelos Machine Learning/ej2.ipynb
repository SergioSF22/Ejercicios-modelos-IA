{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. Predicción del Costo del Seguro Médico con Regresión Lineal Múltiple\n",
    "    \n",
    "    Eres un analista de datos en una empresa de seguros médicos. Tu objetivo es desarrollar un modelo de **Regresión Lineal Múltiple** que permita predecir el **costo del seguro médico** (`charges`) en función de varias características de los clientes, como su edad, índice de masa corporal (IMC), número de hijos y si son fumadores o no.\n",
    "    \n",
    "    El dataset `insurance.csv` (https://www.kaggle.com/datasets/mirichoi0218/insurance?resource=download) contiene la siguiente información:\n",
    "    \n",
    "    - **`age`** → Edad del cliente.\n",
    "    - **`sex`** → Género (`male` o `female`).\n",
    "    - **`bmi`** → Índice de masa corporal (IMC).\n",
    "    - **`children`** → Número de hijos que tiene el cliente asegurado.\n",
    "    - **`smoker`** → Si el cliente es fumador (`yes/no`).\n",
    "    - **`region`** → Región geográfica donde reside el cliente (`northeast, northwest, southeast, southwest`).\n",
    "    - **`charges`** → Costo del seguro médico (variable objetivo).\n",
    "    \n",
    "    Debes entrenar un modelo de **Regresión Lineal Múltiple** para predecir `charges` en función de las variables disponibles y evaluar su rendimiento con métricas como MAE, MSE y R².\n",
    "    \n",
    "    ### INSTRUCCIONES\n",
    "    \n",
    "    1. **Cargar el dataset `insurance.csv`** desde la URL [pública o Kaggle**.**](https://www.kaggle.com/datasets/mirichoi0218/insurance?resource=download)\n",
    "    2. **Explorar los datos y convertir las variables categóricas (`sex`, `smoker`, `region`) a variables numéricas** mediante **One-Hot Encoding**.\n",
    "    3. **Seleccionar las variables predictoras (`X`) y la variable objetivo (`y`).**\n",
    "    4. **Escalar las variables numéricas** utilizando `StandardScaler()`.\n",
    "    5. **Dividir el dataset en conjuntos de entrenamiento (80%) y prueba (20%)** usando `train_test_split()`.\n",
    "    6. **Entrenar un modelo de Regresión Lineal** con `LinearRegression()` de `sklearn`.\n",
    "    7. **Obtener e interpretar los coeficientes y el intercepto del modelo.**\n",
    "    8. **Realizar predicciones con el conjunto de prueba (`X_test`).**\n",
    "    9. **Evaluar el modelo utilizando las métricas:**\n",
    "        - **MAE (Error Absoluto Medio)**\n",
    "        - **MSE (Error Cuadrático Medio)**\n",
    "        - **RMSE (Raíz del Error Cuadrático Medio)**\n",
    "        - **R² (Coeficiente de Determinación)**\n",
    "    \n",
    "    ### **PISTAS Y CONSEJOS**\n",
    "    \n",
    "    - Para convertir las variables categóricas a numéricas, usa `pd.get_dummies()`.\n",
    "    - Al hacerlo, asegúrate de eliminar una categoría de cada variable categórica para evitar colinealidad (`drop_first=True`): `df = pd.get_dummies(df, drop_first=True)`\n",
    "    - Analiza el impacto de cada variable en la predicción revisando los coeficientes del modelo.\n",
    "    - Si el R² es bajo, ¿qué podrías hacer para mejorar el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age    sex     bmi  children  smoker      charges  northwest  southeast  \\\n",
      "0      19  False  27.900         0    True  16884.92400      False      False   \n",
      "1      18   True  33.770         1   False   1725.55230      False       True   \n",
      "2      28   True  33.000         3   False   4449.46200      False       True   \n",
      "3      33   True  22.705         0   False  21984.47061       True      False   \n",
      "4      32   True  28.880         0   False   3866.85520       True      False   \n",
      "...   ...    ...     ...       ...     ...          ...        ...        ...   \n",
      "1333   50   True  30.970         3   False  10600.54830       True      False   \n",
      "1334   18  False  31.920         0   False   2205.98080      False      False   \n",
      "1335   18  False  36.850         0   False   1629.83350      False       True   \n",
      "1336   21  False  25.800         0   False   2007.94500      False      False   \n",
      "1337   61  False  29.070         0    True  29141.36030       True      False   \n",
      "\n",
      "      southwest  \n",
      "0          True  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "...         ...  \n",
      "1333      False  \n",
      "1334      False  \n",
      "1335      False  \n",
      "1336       True  \n",
      "1337      False  \n",
      "\n",
      "[1338 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' # Seleccionar variables independientes (X) y la variable objetivo (y)\\nX = df.drop(columns=[\"charges\"])  # Variables predictoras\\ny = df[\"charges\"]  # Variable objetivo\\n\\n# Comprobamos el rango de valores de la variable objetivo\\nprint(f\"Valor mínimo de DiseaseProgression: {y.min()}\")\\nprint(f\"Valor máximo de DiseaseProgression: {y.max()}\")\\n\\n# Escalar las variables independientes con StandardScaler()\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X) # Devuelve un array NumPy\\nprint(f\"Tamaño de X_scaled: {X_scaled.shape}, Tamaño de y: {y.shape}\") # Asegurar que X_scaled y y tienen el mismo número de filas\\n\\n# Calcular la correlación con la variable objetivo\\ndf_scaled = pd.DataFrame(X_scaled, columns=X.columns) \\ndf_scaled[\"DiseaseProgression\"] = y  # Agregamos la variable objetivo para calcular correlación\\ncorrelaciones = df_scaled.corr()[\"DiseaseProgression\"].sort_values(ascending=False)\\n\\n# Mostrar la correlación de cada variable con la variable objetivo\\nprint(\"Correlaciones con la variable objetivo:\")\\nprint(correlaciones)\\n\\n# Calcular el VIF para detectar colinealidad entre variables\\nvif_data = pd.DataFrame()\\nvif_data[\"Variable\"] = X.columns\\nvif_data[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\\n\\n# Mostrar los resultados\\nprint(\"VIF de cada variable:\")\\nprint(vif_data)\\n\\n# Dividir el dataset en entrenamiento (80%) y prueba (20%) con train_test_split()\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\\n\\n# Entrenar el modelo de Regresión Lineal con LinearRegression()\\nmodelo = LinearRegression()\\nmodelo.fit(X_train, y_train)\\n\\n# Obtener e interpretar los coeficientes y el intercepto del modelo\\ncoeficientes = pd.Series(modelo.coef_, index=X.columns)\\n\\nprint(\"Intercepto:\", modelo.intercept_)\\nprint(\"Coeficientes del modelo:\")\\nprint(coeficientes)\\n\\n# Realizar predicciones con modelo.predict(X_test)\\ny_pred = modelo.predict(X_test)\\n\\n# Evaluar el modelo \\nmae = mean_absolute_error(y_test, y_pred)\\nmse = mean_squared_error(y_test, y_pred)\\nrmse = np.sqrt(mse)\\nr2 = r2_score(y_test, y_pred)\\n\\n# Mostrar resultados\\nprint(f\"MAE (Error Absoluto Medio): {mae:.4f}\")\\nprint(f\"MSE (Error Cuadrático Medio): {mse:.4f}\")\\nprint(f\"RMSE (Raíz del Error Cuadrático Medio): {rmse:.4f}\")\\nprint(f\"R² (Coeficiente de Determinación): {r2:.4f}\") '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Cargar el CSV en un dataset\n",
    "df = pd.read_csv(\"Medical_Cost.csv\")\n",
    "\n",
    "# Mediante One-Hot encoding convertimos las variables categóricas a variables numéricas eliminando la columna origen en el proceso mediante el parámetro 'drop_first=True'\n",
    "onehot_sex = pd.get_dummies(df[\"sex\"], drop_first=True)\n",
    "onehot_region = pd.get_dummies(df[\"region\"], drop_first=True)\n",
    "onehot_smoker = pd.get_dummies(df[\"smoker\"], drop_first=True)\n",
    "# Sustituimos las columnas 'sex' y 'smoker' por el sataframe encodeado ya que solo posee una columna\n",
    "df[\"sex\"] = onehot_sex\n",
    "df[\"smoker\"] = onehot_smoker\n",
    "# Ya que la columna 'region' encodeada posee 3 columnas debemos añadirla al DataFrame original con otro método (concat), asi que primero eliminamos la orignal con drop() y luego añadimos la columna\n",
    "df = df.drop(['region'], axis=1)\n",
    "df = pd.concat([df, onehot_region], axis=1)\n",
    "print(df)\n",
    "\n",
    "\"\"\" # Seleccionar variables independientes (X) y la variable objetivo (y)\n",
    "X = df.drop(columns=[\"charges\"])  # Variables predictoras\n",
    "y = df[\"charges\"]  # Variable objetivo\n",
    "\n",
    "# Comprobamos el rango de valores de la variable objetivo\n",
    "print(f\"Valor mínimo de DiseaseProgression: {y.min()}\")\n",
    "print(f\"Valor máximo de DiseaseProgression: {y.max()}\")\n",
    "\n",
    "# Escalar las variables independientes con StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) # Devuelve un array NumPy\n",
    "print(f\"Tamaño de X_scaled: {X_scaled.shape}, Tamaño de y: {y.shape}\") # Asegurar que X_scaled y y tienen el mismo número de filas\n",
    "\n",
    "# Calcular la correlación con la variable objetivo\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns) \n",
    "df_scaled[\"DiseaseProgression\"] = y  # Agregamos la variable objetivo para calcular correlación\n",
    "correlaciones = df_scaled.corr()[\"DiseaseProgression\"].sort_values(ascending=False)\n",
    "\n",
    "# Mostrar la correlación de cada variable con la variable objetivo\n",
    "print(\"Correlaciones con la variable objetivo:\")\n",
    "print(correlaciones)\n",
    "\n",
    "# Calcular el VIF para detectar colinealidad entre variables\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"VIF de cada variable:\")\n",
    "print(vif_data)\n",
    "\n",
    "# Dividir el dataset en entrenamiento (80%) y prueba (20%) con train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de Regresión Lineal con LinearRegression()\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Obtener e interpretar los coeficientes y el intercepto del modelo\n",
    "coeficientes = pd.Series(modelo.coef_, index=X.columns)\n",
    "\n",
    "print(\"Intercepto:\", modelo.intercept_)\n",
    "print(\"Coeficientes del modelo:\")\n",
    "print(coeficientes)\n",
    "\n",
    "# Realizar predicciones con modelo.predict(X_test)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo \n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"MAE (Error Absoluto Medio): {mae:.4f}\")\n",
    "print(f\"MSE (Error Cuadrático Medio): {mse:.4f}\")\n",
    "print(f\"RMSE (Raíz del Error Cuadrático Medio): {rmse:.4f}\")\n",
    "print(f\"R² (Coeficiente de Determinación): {r2:.4f}\") \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
