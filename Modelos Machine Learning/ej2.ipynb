{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. Predicción del Costo del Seguro Médico con Regresión Lineal Múltiple\n",
    "    \n",
    "    Eres un analista de datos en una empresa de seguros médicos. Tu objetivo es desarrollar un modelo de **Regresión Lineal Múltiple** que permita predecir el **costo del seguro médico** (`charges`) en función de varias características de los clientes, como su edad, índice de masa corporal (IMC), número de hijos y si son fumadores o no.\n",
    "    \n",
    "    El dataset `insurance.csv` (https://www.kaggle.com/datasets/mirichoi0218/insurance?resource=download) contiene la siguiente información:\n",
    "    \n",
    "    - **`age`** → Edad del cliente.\n",
    "    - **`sex`** → Género (`male` o `female`).\n",
    "    - **`bmi`** → Índice de masa corporal (IMC).\n",
    "    - **`children`** → Número de hijos que tiene el cliente asegurado.\n",
    "    - **`smoker`** → Si el cliente es fumador (`yes/no`).\n",
    "    - **`region`** → Región geográfica donde reside el cliente (`northeast, northwest, southeast, southwest`).\n",
    "    - **`charges`** → Costo del seguro médico (variable objetivo).\n",
    "    \n",
    "    Debes entrenar un modelo de **Regresión Lineal Múltiple** para predecir `charges` en función de las variables disponibles y evaluar su rendimiento con métricas como MAE, MSE y R².\n",
    "    \n",
    "    ### INSTRUCCIONES\n",
    "    \n",
    "    1. **Cargar el dataset `insurance.csv`** desde la URL [pública o Kaggle**.**](https://www.kaggle.com/datasets/mirichoi0218/insurance?resource=download)\n",
    "    2. **Explorar los datos y convertir las variables categóricas (`sex`, `smoker`, `region`) a variables numéricas** mediante **One-Hot Encoding**.\n",
    "    3. **Seleccionar las variables predictoras (`X`) y la variable objetivo (`y`).**\n",
    "    4. **Escalar las variables numéricas** utilizando `StandardScaler()`.\n",
    "    5. **Dividir el dataset en conjuntos de entrenamiento (80%) y prueba (20%)** usando `train_test_split()`.\n",
    "    6. **Entrenar un modelo de Regresión Lineal** con `LinearRegression()` de `sklearn`.\n",
    "    7. **Obtener e interpretar los coeficientes y el intercepto del modelo.**\n",
    "    8. **Realizar predicciones con el conjunto de prueba (`X_test`).**\n",
    "    9. **Evaluar el modelo utilizando las métricas:**\n",
    "        - **MAE (Error Absoluto Medio)**\n",
    "        - **MSE (Error Cuadrático Medio)**\n",
    "        - **RMSE (Raíz del Error Cuadrático Medio)**\n",
    "        - **R² (Coeficiente de Determinación)**\n",
    "    \n",
    "    ### **PISTAS Y CONSEJOS**\n",
    "    \n",
    "    - Para convertir las variables categóricas a numéricas, usa `pd.get_dummies()`.\n",
    "    - Al hacerlo, asegúrate de eliminar una categoría de cada variable categórica para evitar colinealidad (`drop_first=True`): `df = pd.get_dummies(df, drop_first=True)`\n",
    "    - Analiza el impacto de cada variable en la predicción revisando los coeficientes del modelo.\n",
    "    - Si el R² es bajo, ¿qué podrías hacer para mejorar el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo de charges: 1121.8739\n",
      "Valor máximo de charges: 63770.42801\n",
      "Tamaño de X_scaled: (1338, 8), Tamaño de y: (1338,)\n",
      "Correlaciones con la variable objetivo:\n",
      "charges      1.000000\n",
      "smoker       0.787251\n",
      "age          0.299008\n",
      "bmi          0.198341\n",
      "southeast    0.073982\n",
      "children     0.067998\n",
      "sex          0.057292\n",
      "northwest   -0.039905\n",
      "southwest   -0.043210\n",
      "Name: charges, dtype: float64\n",
      "VIF de cada variable:\n",
      "    Variable       VIF\n",
      "0        age  1.016822\n",
      "1        sex  1.008900\n",
      "2        bmi  1.106630\n",
      "3   children  1.004011\n",
      "4     smoker  1.012074\n",
      "5  northwest  1.518823\n",
      "6  southeast  1.652230\n",
      "7  southwest  1.529411\n",
      "Intercepto: 13314.335941867355\n",
      "Coeficientes del modelo:\n",
      "smoker       9544.251089\n",
      "age          3609.149018\n",
      "bmi          2054.885063\n",
      "children      512.478869\n",
      "sex            -9.295337\n",
      "northwest    -158.959435\n",
      "southeast    -292.759080\n",
      "southwest    -347.270359\n",
      "dtype: float64\n",
      "MAE (Error Absoluto Medio): 4181.1945\n",
      "MSE (Error Cuadrático Medio): 33596915.8514\n",
      "RMSE (Raíz del Error Cuadrático Medio): 5796.2847\n",
      "R² (Coeficiente de Determinación): 0.7836\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Cargar el CSV en un dataset\n",
    "df = pd.read_csv(\"Medical_Cost.csv\")\n",
    "\n",
    "# Mediante One-Hot encoding convertimos las variables categóricas a variables numéricas eliminando la columna origen en el proceso mediante el parámetro 'drop_first=True'\n",
    "onehot_sex = pd.get_dummies(df[\"sex\"], drop_first=True)\n",
    "onehot_region = pd.get_dummies(df[\"region\"], drop_first=True)\n",
    "onehot_smoker = pd.get_dummies(df[\"smoker\"], drop_first=True)\n",
    "# Sustituimos las columnas 'sex' y 'smoker' por el sataframe encodeado ya que solo posee una columna\n",
    "df[\"sex\"] = onehot_sex\n",
    "df[\"smoker\"] = onehot_smoker\n",
    "# Ya que la columna 'region' encodeada posee 3 columnas debemos añadirla al DataFrame original con otro método (concat), asi que primero eliminamos la orignal con drop() y luego añadimos la columna\n",
    "df = df.drop(['region'], axis=1)\n",
    "df = pd.concat([df, onehot_region], axis=1)\n",
    "\n",
    "# Seleccionar variables independientes (X) y la variable objetivo (y)\n",
    "X = df.drop(columns=[\"charges\"])  # Variables predictoras\n",
    "y = df[\"charges\"]  # Variable objetivo\n",
    "\n",
    "# Comprobamos el rango de valores de la variable objetivo\n",
    "print(f\"Valor mínimo de charges: {y.min()}\")\n",
    "print(f\"Valor máximo de charges: {y.max()}\")\n",
    "\n",
    "# Escalar las variables independientes con StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) # Devuelve un array NumPy\n",
    "print(f\"Tamaño de X_scaled: {X_scaled.shape}, Tamaño de y: {y.shape}\") # Asegurar que X_scaled y y tienen el mismo número de filas\n",
    "\n",
    "# Calcular la correlación con la variable objetivo\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns) \n",
    "df_scaled[\"charges\"] = y  # Agregamos la variable objetivo para calcular correlación\n",
    "correlaciones = df_scaled.corr()[\"charges\"].sort_values(ascending=False)\n",
    "\n",
    "# Mostrar la correlación de cada variable con la variable objetivo\n",
    "print(\"Correlaciones con la variable objetivo:\")\n",
    "print(correlaciones)\n",
    "\n",
    "# Calcular el VIF para detectar colinealidad entre variables\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"VIF de cada variable:\")\n",
    "print(vif_data)\n",
    "\n",
    "# Dividir el dataset en entrenamiento (80%) y prueba (20%) con train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de Regresión Lineal con LinearRegression()\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Obtener e interpretar los coeficientes y el intercepto del modelo\n",
    "coeficientes = pd.Series(modelo.coef_, index=X.columns)\n",
    "\n",
    "print(\"Intercepto:\", modelo.intercept_)\n",
    "print(\"Coeficientes del modelo:\")\n",
    "print(coeficientes.sort_values(ascending=False))\n",
    "\n",
    "# Realizar predicciones con modelo.predict(X_test)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo \n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"MAE (Error Absoluto Medio): {mae:.4f}\")\n",
    "print(f\"MSE (Error Cuadrático Medio): {mse:.4f}\")\n",
    "print(f\"RMSE (Raíz del Error Cuadrático Medio): {rmse:.4f}\")\n",
    "print(f\"R² (Coeficiente de Determinación): {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
