{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regresión logística para predecir supervivientes en accidentes \n",
    "\n",
    "### CONTEXTO\n",
    "\n",
    "Para la realización de este ejercicio simularemos que trabajas en el INE y que a partir de los datos de un dataset de accidentes vas a predecir la cantidad de supervivientes de accidentes en función del año, género, la velocidad del impacto y el uso de casco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Age              200 non-null    int64  \n",
      " 1   Gender           199 non-null    object \n",
      " 2   Speed_of_Impact  197 non-null    float64\n",
      " 3   Helmet_Used      200 non-null    object \n",
      " 4   Seatbelt_Used    200 non-null    object \n",
      " 5   Survived         200 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "             Age  Speed_of_Impact   Survived\n",
      "count  200.00000       197.000000  200.00000\n",
      "mean    43.42500        70.441624    0.50500\n",
      "std     14.94191        30.125298    0.50123\n",
      "min     18.00000        20.000000    0.00000\n",
      "25%     31.00000        43.000000    0.00000\n",
      "50%     43.50000        71.000000    1.00000\n",
      "75%     56.00000        95.000000    1.00000\n",
      "max     69.00000       119.000000    1.00000\n",
      "Age: [56 69 46 32 60 25 38 36 40 28 41 53 57 20 39 19 61 47 55 50 29 44 59 45\n",
      " 33 64 68 54 24 26 35 21 42 31 67 43 37 52 34 23 51 27 48 65 62 58 18 22\n",
      " 30 49 66]\n",
      "Gender: ['Female' 'Male']\n",
      "Speed_of_Impact: [ 27.  46. 117.  40.  49. 116.  47.  83.  88.  80.  67.  38.  23.  68.\n",
      "  36. 111. 112.  65.  25. 118.  56.  43. 114.  79.  82. 104.  51. 106.\n",
      "  52.  86.  37.  44.  73.  77.  66. 105.  42.  85.  21. 109.  28.  62.\n",
      "  58.  61.  45.  69.  32.  26.  76.  55.  64.  39.  84.  35.  33.  95.\n",
      "  34.  70.  81.  41.  71.  89.  72.  24.  87. 115. 113.  74.  59.  31.\n",
      "  20.  53. 108.  48.  97. 119.  29.  99. 110. 103.]\n",
      "Helmet_Used: ['No' 'Yes']\n",
      "Seatbelt_Used: ['No' 'Yes']\n",
      "Survived: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el CSV\n",
    "df = pd.read_csv(\"accident.csv\")\n",
    "\n",
    "# Analizamos el contenido del mismo\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Eliminamos los registros con valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Imprimimos los valores únicos de cada variable para determinar su tipo (categórica o numérica)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinamos que las variables numéricas son ``Age`` y ``Speed_of_Impact`` y las categóricas son ``Gender``, ``Helmet_Used`` y ``Seatbelt_Used``. <br>\n",
    "Nuestra variable a predecir es ``Survived``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con Sobremuestreo Aleatorio:\n",
      "Accuracy: 50.00%\n",
      "Precision: 40.00%\n",
      "Recall: 66.67%\n",
      "F1-Score: 50.00%\n",
      "AUC-ROC: 53.33%\n",
      "\n",
      "Resultados con SMOTE:\n",
      "Accuracy: 55.00%\n",
      "Precision: 43.48%\n",
      "Recall: 66.67%\n",
      "F1-Score: 52.63%\n",
      "AUC-ROC: 52.80%\n",
      "\n",
      "Resultados con Submuestreo Aleatorio:\n",
      "Accuracy: 60.00%\n",
      "Precision: 47.83%\n",
      "Recall: 73.33%\n",
      "F1-Score: 57.89%\n",
      "AUC-ROC: 56.53%\n",
      "\n",
      "Resultados con NearMiss:\n",
      "Accuracy: 55.00%\n",
      "Precision: 43.48%\n",
      "Recall: 66.67%\n",
      "F1-Score: 52.63%\n",
      "AUC-ROC: 60.53%\n",
      "\n",
      "El mejor método de balanceo es: Submuestreo Aleatorio con F1-Score: 57.89% y AUC-ROC: 56.53%\n",
      "\n",
      "Resultados con ajuste manual de hiperparámetros:\n",
      "Accuracy: 60.00%\n",
      "Precision: 47.83%\n",
      "Recall: 73.33%\n",
      "F1-Score: 57.89%\n",
      "AUC-ROC: 56.53%\n",
      "\n",
      "Resultados con ajuste automático de hiperparámetros:\n",
      "Mejores parámetros: {'C': 0.01, 'solver': 'liblinear'}\n",
      "Mejor Accuracy en validación cruzada: 54.93%\n",
      "Accuracy: 57.50%\n",
      "Precision: 45.45%\n",
      "Recall: 66.67%\n",
      "F1-Score: 54.05%\n",
      "AUC-ROC: 54.93%\n",
      "        Real Predicción\n",
      "0  Fallecido  Fallecido\n",
      "1  Fallecido  Fallecido\n",
      "2  Fallecido       Vivo\n",
      "3  Fallecido       Vivo\n",
      "4  Fallecido       Vivo\n",
      "5  Fallecido       Vivo\n",
      "6  Fallecido       Vivo\n",
      "7  Fallecido       Vivo\n",
      "8  Fallecido       Vivo\n",
      "9       Vivo       Vivo\n"
     ]
    }
   ],
   "source": [
    "# Encodeamos las variables categóricas mediante OneHot Encoder. Usamos el parámetro 'drop_first' para eliminar la primera columna generada y evitar redundancias\n",
    "categoricas = [\"Gender\", \"Helmet_Used\", \"Seatbelt_Used\"]\n",
    "for cat in categoricas:\n",
    "    df[cat] = pd.get_dummies(df[cat], drop_first=True)\n",
    "\n",
    "# Elegimos la variables predictoras junto con la variable a predecir\n",
    "X = df.drop(columns=[\"Survived\"])\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "# Preprocesamos las variables numéricas mediante el StandarScaler para que esten en la misma escala\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------\n",
    "# MÉTODOS DE BALANCEO DE CLASES\n",
    "# --------------------\n",
    "# 1. Sobremuestreo aleatorio\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Submuestreo aleatorio\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 4. NearMiss (submuestreo basado en distancia)\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# EVALUACIÓN DE MÉTODOS DE BALANCEO\n",
    "# --------------------\n",
    "resultados_balanceo = {}\n",
    "\n",
    "def evaluar_balanceo(X_train_resampled, y_train_resampled, metodo):\n",
    "    # Creación del modelo de RL\n",
    "    model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)\n",
    "    # Entreno el modelo con los datos de cada modelo\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    # Realizo predicciones con el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculo la precisión del modelo sacando las métricas\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1]) * 100\n",
    "    resultados_balanceo[metodo] = (f1, auc)\n",
    "    # Imprimimos los resultados\n",
    "    print(f\"\\nResultados con {metodo}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred) * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {f1:.2f}%\")\n",
    "    print(f\"AUC-ROC: {auc:.2f}%\")\n",
    "\n",
    "evaluar_balanceo(X_train_ros, y_train_ros, \"Sobremuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "evaluar_balanceo(X_train_rus, y_train_rus, \"Submuestreo Aleatorio\")\n",
    "evaluar_balanceo(X_train_nm, y_train_nm, \"NearMiss\")\n",
    "\n",
    "# Seleccionar el mejor método de balanceo\n",
    "mejor_metodo = max(resultados_balanceo, key=lambda k: resultados_balanceo[k])\n",
    "print(f\"\\nEl mejor método de balanceo es: {mejor_metodo} con F1-Score: {resultados_balanceo[mejor_metodo][0]:.2f}% y AUC-ROC: {resultados_balanceo[mejor_metodo][1]:.2f}%\")\n",
    "\n",
    "# Obtener los datos balanceados del mejor método encontrado\n",
    "if mejor_metodo == \"Sobremuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_ros, y_train_ros\n",
    "elif mejor_metodo == \"SMOTE\":\n",
    "    X_train_resampled, y_train_resampled = X_train_smote, y_train_smote\n",
    "elif mejor_metodo == \"Submuestreo Aleatorio\":\n",
    "    X_train_resampled, y_train_resampled = X_train_rus, y_train_rus\n",
    "elif mejor_metodo == \"NearMiss\":\n",
    "    X_train_resampled, y_train_resampled = X_train_nm, y_train_nm\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 1: Ajuste manual de hiperparámetros\n",
    "# --------------------\n",
    "manual_model = LogisticRegression(C=0.1, solver='liblinear', max_iter=500)  # Ejemplo de hiperparámetros ajustados manualmente\n",
    "manual_model.fit(X_train_resampled, y_train_resampled)  # Entrenar modelo\n",
    "\n",
    "# Predicciones\n",
    "y_pred_manual = manual_model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo ajustado manualmente\n",
    "print(\"\\nResultados con ajuste manual de hiperparámetros:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_manual) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, manual_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "# --------------------\n",
    "# MÉTODO 2: Ajuste automático con GridSearchCV\n",
    "# --------------------\n",
    "parametros = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Diferentes valores de regularización\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"]  # Diferentes algoritmos de optimización\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=500), parametros, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)  # Entrenar búsqueda de hiperparámetros\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación del mejor modelo\n",
    "print(\"\\nResultados con ajuste automático de hiperparámetros:\")\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor Accuracy en validación cruzada: {grid_search.best_score_ * 100:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best) * 100:.2f}%\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# ENTRENAMIENTO FINAL Y EVALUACIÓN\n",
    "# --------------------\n",
    "\n",
    "# Entrenar el mejor modelo con los datos balanceados\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Realizar predicciones finales con el mejor modelo y el mejor balanceo\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "resultados = pd.DataFrame({\n",
    "    \"Real\": y_test.values,\n",
    "    \"Predicción\": y_pred_final\n",
    "})\n",
    "\n",
    "# Mapear valores 0 y 1 a etiquetas comprensibles\n",
    "resultados[\"Real\"] = resultados[\"Real\"].map({0: \"Fallecido\", 1: \"Vivo\"})\n",
    "resultados[\"Predicción\"] = resultados[\"Predicción\"].map({0: \"Fallecido\", 1: \"Vivo\"})\n",
    "\n",
    "# Mostrar las primeras filas de la tabla\n",
    "print(resultados.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
